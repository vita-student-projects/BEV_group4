{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3e5e63e-f7d9-4ccb-b2bd-e3f015bf92ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/deepakduggirala/Documents/autonomous-robotics/translating-images-into-maps\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f106c23c-2386-4ae7-9c02-0d72d2f6d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lmdb\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from nuscenes.nuscenes import NuScenes\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "229b1725-9cc4-41ab-95ad-96cbf7062ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.dataloader import nuScenesMaps, read_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db1d12b9-92bb-4a57-b78e-75e4f52c86f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = Path.resolve(Path('/Users/deepakduggirala/Documents/autonomous-robotics/v1.0-trainval_meta/'))\n",
    "nusc = NuScenes(version='v1.0-trainval', dataroot=data_root, verbose=False)\n",
    "tokens = read_split(\n",
    "            os.path.join(data_root, \"splits\", \"{}.txt\".format('evaluation'))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0376cf5e-e1c6-4c90-860d-2a5a5cd1ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_bytes(im):\n",
    "    byteImgIO = io.BytesIO()\n",
    "    im.save(byteImgIO, \"PNG\")\n",
    "    return byteImgIO.getvalue()\n",
    "\n",
    "def image_from_bytes(img_bytes):\n",
    "    return Image.open(io.BytesIO(img_bytes)).convert(mode='RGB')\n",
    "\n",
    "def img_equal(im1, im2):\n",
    "    return torch.all(to_tensor(im1) == to_tensor(im2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6d1e316-dad2-4e56-8d83-8ccc7f6b8a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs nusc, data_root\n",
    "def get_cam_front_path(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    cam_front_token = sample['data']['CAM_FRONT']\n",
    "    cam_front_data = nusc.get('sample_data', cam_front_token)\n",
    "    cam_front_path = (data_root / Path(cam_front_data['filename']))\n",
    "    return cam_front_path\n",
    "\n",
    "\n",
    "def get_key_value(sample_token):\n",
    "    cam_front_path = get_cam_front_path(sample_token)\n",
    "    \n",
    "    im = Image.open(str(cam_front_path))\n",
    "    im_bytes = image_to_bytes(im)\n",
    "    \n",
    "    key_bytes = bytes(cam_front_path.stem, 'utf-8')\n",
    "    \n",
    "    return key_bytes, im_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a27a038-45d4-4853-b01b-37a270597bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_db_path = os.path.join(\n",
    "            data_root, \"lmdb\",\n",
    "            \"samples\", \"CAM_FRONT\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10f38b59-f4e0-4e64-af0d-3f5d09000bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 images put into lmdb. 8.46 MB written.\n",
      "20 images put into lmdb. 17.37 MB written.\n",
      "30 images put into lmdb. 27.51 MB written.\n",
      "40 images put into lmdb. 37.07 MB written.\n",
      "50 images put into lmdb. 49.32 MB written.\n",
      "60 images put into lmdb. 59.09 MB written.\n",
      "CPU times: user 17.7 s, sys: 143 ms, total: 17.8 s\n",
      "Wall time: 18.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "total_bytes = 0\n",
    "with lmdb.open(path=images_db_path, map_size = int(1 * 1024 * 1024 * 1024)) as images_db:\n",
    "    with images_db.begin(write=True) as txn:\n",
    "        for i,sample_token in enumerate(tokens):\n",
    "            key, value = get_key_value(sample_token)\n",
    "            total_bytes += len(key) + len(value)\n",
    "            txn.put(key, value)\n",
    "            if (i+1)%10==0:\n",
    "                print(f'{i+1} images put into lmdb. {total_bytes/(1024*1024):.2f} MB written.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2349e-7e51-4e5b-b393-a63e2cd63cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = get_cam_front_path(tokens[50]).stem.encode('utf-8')\n",
    "images_db_path='/Users/deepakduggirala/Documents/autonomous-robotics/v1.0-mini/lmdb/samples/CAM_FRONT'\n",
    "with lmdb.open(path=str(images_db_path), \n",
    "               readonly=True, \n",
    "               readahead=False,\n",
    "               max_spare_txns=128,) as images_db:\n",
    "    with images_db.begin() as txn:\n",
    "        im_read = txn.get(key)\n",
    "        \n",
    "image_from_bytes(im_read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8354ba-b21e-41cb-863b-21314868281f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd88e60-28e0-487e-ad8b-42e4e0b73238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919359e2-e73f-48dd-b1dd-4fd1f40638d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83022282-6783-4392-ba08-2d9ee73d5427",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cam_front_data(sample_token):\n",
    "    sample = nusc.get('sample', sample_token)\n",
    "    cam_front_token = sample['data']['CAM_FRONT']\n",
    "    cam_front_data = nusc.get('sample_data', cam_front_token)\n",
    "    calib = nusc.get(\"calibrated_sensor\", cam_front_data[\"calibrated_sensor_token\"])[\"camera_intrinsic\"]\n",
    "    \n",
    "    return {\n",
    "        'filename': cam_front_data['filename'], \n",
    "        'calib': calib\n",
    "    }\n",
    "eval_data = {token:get_cam_front_data(token) for token in tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9a0e349-25a2-4a49-aa40-8d952c39f654",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('eval_data.pickle', 'wb') as f:\n",
    "    pickle.dump(eval_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1e5ab1-f59b-49e0-b6b3-5f23a1bd3545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f736c8af-d5b1-467a-989a-50136cd2109f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41b28f61-6275-4ebf-b027-230a1d9b11d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'samples/CAM_FRONT/n008-2018-09-18-15-12-01-0400__CAM_FRONT__1537298218412404.jpg' 'samples/CAM_FRONT/n015-2018-07-24-11-03-52+0800__CAM_FRONT__1532401508412460.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657117612404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-15-12-01-0400__CAM_FRONT__1537298355612404.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731138162404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290827412404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290892912404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-15-12-01-0400__CAM_FRONT__1537298128162404.jpg' 'samples/CAM_FRONT/n015-2018-07-18-11-50-34+0800__CAM_FRONT__1531885919612469.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657278662404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290844162404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-14-43-59-0400__CAM_FRONT__1537296540162404.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731405612404.jpg' 'samples/CAM_FRONT/n015-2018-09-25-13-17-43+0800__CAM_FRONT__1537852785162460.jpg' 'samples/CAM_FRONT/n015-2018-09-25-13-17-43+0800__CAM_FRONT__1537852774612460.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-31-50-0400__CAM_FRONT__1535657533512404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290951162404.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-37-23-0400__CAM_FRONT__1535730283912404.jpg' 'samples/CAM_FRONT/n015-2018-07-24-11-13-19+0800__CAM_FRONT__1532402424612460.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656620262404.jpg' 'samples/CAM_FRONT/n015-2018-10-02-10-50-40+0800__CAM_FRONT__1538448761512460.jpg' 'samples/CAM_FRONT/n015-2018-07-11-11-54-16+0800__CAM_FRONT__1531281496262460.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290741262404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537291073662404.jpg' 'samples/CAM_FRONT/n015-2018-08-03-15-00-36+0800__CAM_FRONT__1533280053162460.jpg' 'samples/CAM_FRONT/n015-2018-09-27-15-33-17+0800__CAM_FRONT__1538034016162460.jpg' 'samples/CAM_FRONT/n008-2018-09-18-14-43-59-0400__CAM_FRONT__1537296660512404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659004512404.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731316612404.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731277162407.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657479262404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290883912404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656641762404.jpg' 'samples/CAM_FRONT/n015-2018-09-27-15-33-17+0800__CAM_FRONT__1538033922662460.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-37-23-0400__CAM_FRONT__1535730331162404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657477762404.jpg' 'samples/CAM_FRONT/n015-2018-09-25-13-17-43+0800__CAM_FRONT__1537852779112460.jpg' 'samples/CAM_FRONT/n015-2018-08-03-15-00-36+0800__CAM_FRONT__1533280040612460.jpg' 'samples/CAM_FRONT/n015-2018-08-01-16-41-59+0800__CAM_FRONT__1533113396862460.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657164162404.jpg' 'samples/CAM_FRONT/n015-2018-10-02-10-50-40+0800__CAM_FRONT__1538448743662460.jpg' 'samples/CAM_FRONT/n015-2018-07-27-11-36-48+0800__CAM_FRONT__1532662962362460.jpg' 'samples/CAM_FRONT/n008-2018-08-31-11-56-46-0400__CAM_FRONT__1535731309162404.jpg' 'samples/CAM_FRONT/n015-2018-11-14-19-09-14+0800__CAM_FRONT__1542194040162460.jpg' 'samples/CAM_FRONT/n015-2018-09-27-15-33-17+0800__CAM_FRONT__1538033992112460.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535656655162404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-31-50-0400__CAM_FRONT__1535657714512404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290865362404.jpg' 'samples/CAM_FRONT/n015-2018-08-01-17-13-57+0800__CAM_FRONT__1533115298012460.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535658852012404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537291139862404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535658983412404.jpg' 'samples/CAM_FRONT/n015-2018-09-27-15-33-17+0800__CAM_FRONT__1538033933762460.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537290781412404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537298865912404.jpg' 'samples/CAM_FRONT/n015-2018-11-14-18-57-54+0800__CAM_FRONT__1542193382362460.jpg' 'samples/CAM_FRONT/n008-2018-09-18-14-43-59-0400__CAM_FRONT__1537296654662404.jpg' 'samples/CAM_FRONT/n015-2018-07-18-11-07-57+0800__CAM_FRONT__1531883537862460.jpg' 'samples/CAM_FRONT/n008-2018-09-18-13-10-39-0400__CAM_FRONT__1537291158512404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659402862404.jpg' 'samples/CAM_FRONT/n008-2018-08-30-15-16-55-0400__CAM_FRONT__1535657187612404.jpg' 'samples/CAM_FRONT/n008-2018-09-18-14-43-59-0400__CAM_FRONT__1537296528612404.jpg' 'samples/CAM_FRONT/n015-2018-11-14-19-09-14+0800__CAM_FRONT__1542194081912460.jpg'\n"
     ]
    }
   ],
   "source": [
    "filenames = [data['filename'] for data in eval_data.values()]\n",
    "print(' '.join([f\"'{filename}'\" for filename in filenames]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
